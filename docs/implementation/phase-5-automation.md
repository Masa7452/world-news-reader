# Phase 5: è‡ªå‹•åŒ–ã¨é‹ç”¨

## æ¦‚è¦
GitHub Actionsã‚’ä½¿ç”¨ã—ã¦ã€ãƒ‡ãƒ¼ã‚¿åé›†ã‹ã‚‰è¨˜äº‹å…¬é–‹ã¾ã§ã®å…¨å·¥ç¨‹ã‚’è‡ªå‹•åŒ–ã—ã¾ã™ã€‚
å®šæœŸå®Ÿè¡Œã€ã‚¨ãƒ©ãƒ¼ç›£è¦–ã€é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ã‚’æ§‹ç¯‰ã—ã€å®‰å®šã—ãŸé‹ç”¨ä½“åˆ¶ã‚’ç¢ºç«‹ã—ã¾ã™ã€‚

## å‰ææ¡ä»¶
- Phase 1-4ãŒå®Œäº†ã—ã¦ã„ã‚‹ã“ã¨
- GitHub ãƒªãƒã‚¸ãƒˆãƒªãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨
- å„ç¨®APIã‚­ãƒ¼ãŒå–å¾—æ¸ˆã¿ã§ã‚ã‚‹ã“ã¨

## å®Ÿè£…ã‚¿ã‚¹ã‚¯

### 5.1 çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

#### 5.1.1 ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆscripts/pipeline.tsï¼‰
```typescript
#!/usr/bin/env tsx
import { config } from 'dotenv';
import { format } from 'date-fns';
import { ja } from 'date-fns/locale';

// ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
config();

// å„å‡¦ç†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import { fetchGuardianArticles } from './fetch_guardian';
import { fetchNYTArticles } from './fetch_nyt';
import { rankTopics } from './rank_topics';
import { buildOutline } from './build_outline';
import { writePost } from './write_post';
import { polishPost } from './polish_post';
import { verifyPost } from './verify_post';
import { publishArticles } from './publish_local';

// ãƒ­ã‚°ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
const log = (message: string, level: 'info' | 'warn' | 'error' = 'info') => {
  const timestamp = format(new Date(), 'yyyy-MM-dd HH:mm:ss', { locale: ja });
  const prefix = level === 'error' ? 'âŒ' : level === 'warn' ? 'âš ï¸' : 'âœ…';
  console.log(`[${timestamp}] ${prefix} ${message}`);
};

// ã‚¨ãƒ©ãƒ¼é€šçŸ¥
const notifyError = async (error: Error, stage: string) => {
  log(`ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ (${stage}): ${error.message}`, 'error');
  
  // Slack/Discordé€šçŸ¥ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  if (process.env.WEBHOOK_URL) {
    await fetch(process.env.WEBHOOK_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        text: `ğŸš¨ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¨ãƒ©ãƒ¼\nã‚¹ãƒ†ãƒ¼ã‚¸: ${stage}\nã‚¨ãƒ©ãƒ¼: ${error.message}`,
      }),
    }).catch(console.error);
  }
};

// ãƒ¡ã‚¤ãƒ³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
const runPipeline = async () => {
  const startTime = Date.now();
  log('=== World News Reader ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹ ===');
  
  const results = {
    guardian: 0,
    nyt: 0,
    topics: 0,
    outlines: 0,
    drafts: 0,
    published: 0,
  };

  try {
    // Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†
    log('Phase 1: ãƒ‡ãƒ¼ã‚¿åé›†ã‚’é–‹å§‹');
    
    // Guardianè¨˜äº‹å–å¾—
    try {
      results.guardian = await fetchGuardianArticles();
      log(`Guardian: ${results.guardian}ä»¶ã®æ–°è¦è¨˜äº‹ã‚’å–å¾—`);
    } catch (error) {
      await notifyError(error as Error, 'Guardianå–å¾—');
    }
    
    // NYTè¨˜äº‹å–å¾—
    try {
      results.nyt = await fetchNYTArticles();
      log(`NYT: ${results.nyt}ä»¶ã®æ–°è¦è¨˜äº‹ã‚’å–å¾—`);
    } catch (error) {
      await notifyError(error as Error, 'NYTå–å¾—');
    }
    
    // ãƒˆãƒ”ãƒƒã‚¯é¸å®š
    if (results.guardian > 0 || results.nyt > 0) {
      results.topics = await rankTopics();
      log(`${results.topics}ä»¶ã®ãƒˆãƒ”ãƒƒã‚¯ã‚’é¸å®š`);
    }
    
    // Phase 2: AIå‡¦ç†
    if (results.topics > 0) {
      log('Phase 2: AIå‡¦ç†ã‚’é–‹å§‹');
      
      // æ§‹æˆç”Ÿæˆ
      results.outlines = await buildOutline();
      log(`${results.outlines}ä»¶ã®æ§‹æˆã‚’ç”Ÿæˆ`);
      
      // è¨˜äº‹åŸ·ç­†
      if (results.outlines > 0) {
        results.drafts = await writePost();
        log(`${results.drafts}ä»¶ã®è¨˜äº‹ã‚’åŸ·ç­†`);
        
        // æ ¡æ­£
        await polishPost();
        log('è¨˜äº‹ã®æ ¡æ­£å®Œäº†');
        
        // æ¤œè¨¼
        const verified = await verifyPost();
        log(`${verified}ä»¶ã®è¨˜äº‹ãŒæ¤œè¨¼ã‚’é€šé`);
      }
    }
    
    // Phase 3: å…¬é–‹
    log('Phase 3: è¨˜äº‹å…¬é–‹ã‚’é–‹å§‹');
    results.published = await publishArticles();
    log(`${results.published}ä»¶ã®è¨˜äº‹ã‚’å…¬é–‹`);
    
    // å®Œäº†
    const duration = Math.round((Date.now() - startTime) / 1000);
    log(`=== ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Œäº† (${duration}ç§’) ===`);
    
    // ã‚µãƒãƒªãƒ¼é€šçŸ¥
    await notifySummary(results, duration);
    
  } catch (error) {
    await notifyError(error as Error, 'ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“');
    process.exit(1);
  }
};

// ã‚µãƒãƒªãƒ¼é€šçŸ¥
const notifySummary = async (results: any, duration: number) => {
  const summary = `
ğŸ“Š ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œçµæœ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Guardianå–å¾—: ${results.guardian}ä»¶
NYTå–å¾—: ${results.nyt}ä»¶
ãƒˆãƒ”ãƒƒã‚¯é¸å®š: ${results.topics}ä»¶
æ§‹æˆç”Ÿæˆ: ${results.outlines}ä»¶
è¨˜äº‹åŸ·ç­†: ${results.drafts}ä»¶
å…¬é–‹: ${results.published}ä»¶
å®Ÿè¡Œæ™‚é–“: ${duration}ç§’
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
`;

  console.log(summary);
  
  if (process.env.WEBHOOK_URL) {
    await fetch(process.env.WEBHOOK_URL, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ text: summary }),
    }).catch(console.error);
  }
};

// å®Ÿè¡Œ
if (require.main === module) {
  runPipeline().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

export { runPipeline };
```

### 5.2 GitHub Actionsè¨­å®š

#### 5.2.1 å®šæœŸå®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆ.github/workflows/scheduled-intake.ymlï¼‰
```yaml
name: Scheduled Article Intake

on:
  schedule:
    # æ—¥æœ¬æ™‚é–“ 6:00 ã¨ 12:00 ã«å®Ÿè¡Œï¼ˆUTC 21:00 ã¨ 3:00ï¼‰
    - cron: '0 21 * * *'
    - cron: '0 3 * * *'
  workflow_dispatch: # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½

env:
  TZ: Asia/Tokyo

jobs:
  intake:
    name: Run Article Intake Pipeline
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run pipeline
        env:
          # API Keys
          GUARDIAN_API_KEY: ${{ secrets.GUARDIAN_API_KEY }}
          NYT_API_KEY: ${{ secrets.NYT_API_KEY }}
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          
          # Supabase
          NEXT_PUBLIC_SUPABASE_URL: ${{ secrets.NEXT_PUBLIC_SUPABASE_URL }}
          NEXT_PUBLIC_SUPABASE_ANON_KEY: ${{ secrets.NEXT_PUBLIC_SUPABASE_ANON_KEY }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          
          # Site
          SITE_URL: ${{ secrets.SITE_URL }}
          
          # Notification (optional)
          WEBHOOK_URL: ${{ secrets.WEBHOOK_URL }}
        run: |
          npx tsx scripts/pipeline.ts

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v3
        with:
          name: pipeline-logs-${{ github.run_id }}
          path: |
            logs/
            *.log

      - name: Notify on failure
        if: failure()
        run: |
          if [ -n "${{ secrets.WEBHOOK_URL }}" ]; then
            curl -X POST ${{ secrets.WEBHOOK_URL }} \
              -H 'Content-Type: application/json' \
              -d '{"text":"ğŸš¨ å®šæœŸå®Ÿè¡Œãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãŒå¤±æ•—ã—ã¾ã—ãŸ\nRun: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}'
          fi
```

#### 5.2.2 æ‰‹å‹•å®Ÿè¡Œãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆ.github/workflows/manual-pipeline.ymlï¼‰
```yaml
name: Manual Pipeline Run

on:
  workflow_dispatch:
    inputs:
      stages:
        description: 'å®Ÿè¡Œã™ã‚‹ã‚¹ãƒ†ãƒ¼ã‚¸'
        required: true
        default: 'all'
        type: choice
        options:
          - all
          - fetch
          - process
          - publish
      debug:
        description: 'ãƒ‡ãƒãƒƒã‚°ãƒ¢ãƒ¼ãƒ‰'
        required: false
        type: boolean
        default: false

jobs:
  run:
    name: Manual Pipeline Execution
    runs-on: ubuntu-latest
    timeout-minutes: 30

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'

      - name: Install dependencies
        run: npm ci

      - name: Run selected stages
        env:
          STAGES: ${{ inputs.stages }}
          DEBUG: ${{ inputs.debug }}
          # ç’°å¢ƒå¤‰æ•°ï¼ˆçœç•¥ï¼‰
        run: |
          if [ "$DEBUG" = "true" ]; then
            export DEBUG='*'
          fi
          
          case "$STAGES" in
            fetch)
              npx tsx scripts/fetch_guardian.ts
              npx tsx scripts/fetch_nyt.ts
              npx tsx scripts/rank_topics.ts
              ;;
            process)
              npx tsx scripts/build_outline.ts
              npx tsx scripts/write_post.ts
              npx tsx scripts/polish_post.ts
              npx tsx scripts/verify_post.ts
              ;;
            publish)
              npx tsx scripts/publish_local.ts
              ;;
            all)
              npx tsx scripts/pipeline.ts
              ;;
          esac
```

#### 5.2.3 ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆ.github/workflows/deploy.ymlï¼‰
```yaml
name: Deploy to Production

on:
  push:
    branches: [main]
  workflow_run:
    workflows: ["Scheduled Article Intake"]
    types: [completed]

jobs:
  deploy:
    name: Deploy to Vercel
    runs-on: ubuntu-latest
    if: ${{ github.event_name == 'push' || github.event.workflow_run.conclusion == 'success' }}

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install Vercel CLI
        run: npm i -g vercel@latest

      - name: Pull Vercel Environment
        run: vercel pull --yes --environment=production --token=${{ secrets.VERCEL_TOKEN }}

      - name: Build Project
        run: vercel build --prod --token=${{ secrets.VERCEL_TOKEN }}

      - name: Deploy to Vercel
        run: vercel deploy --prebuilt --prod --token=${{ secrets.VERCEL_TOKEN }}
```

### 5.3 ç›£è¦–ã¨ãƒ­ã‚°

#### 5.3.1 ãƒ­ã‚°ç®¡ç†ï¼ˆscripts/utils/logger.tsï¼‰
```typescript
import { createWriteStream, existsSync, mkdirSync } from 'fs';
import { join } from 'path';
import { format } from 'date-fns';

export class Logger {
  private logStream: NodeJS.WritableStream;
  private logDir = join(process.cwd(), 'logs');

  constructor(private name: string) {
    // ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    if (!existsSync(this.logDir)) {
      mkdirSync(this.logDir, { recursive: true });
    }

    // ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ
    const logFile = join(
      this.logDir,
      `${name}-${format(new Date(), 'yyyy-MM-dd')}.log`
    );
    this.logStream = createWriteStream(logFile, { flags: 'a' });
  }

  private write(level: string, message: string, data?: any) {
    const timestamp = new Date().toISOString();
    const logEntry = {
      timestamp,
      level,
      name: this.name,
      message,
      ...(data && { data }),
    };

    // ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›
    console.log(`[${level}] ${message}`, data || '');

    // ãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    this.logStream.write(JSON.stringify(logEntry) + '\n');
  }

  info(message: string, data?: any) {
    this.write('INFO', message, data);
  }

  warn(message: string, data?: any) {
    this.write('WARN', message, data);
  }

  error(message: string, error?: Error) {
    this.write('ERROR', message, {
      error: error?.message,
      stack: error?.stack,
    });
  }

  close() {
    this.logStream.end();
  }
}
```

#### 5.3.2 ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ï¼ˆsrc/app/api/health/route.tsï¼‰
```typescript
import { NextResponse } from 'next/server';
import { supabase } from '@/lib/supabase';

export async function GET() {
  const checks = {
    status: 'healthy',
    timestamp: new Date().toISOString(),
    checks: {
      database: false,
      articles: 0,
      lastPublished: null as string | null,
    },
  };

  try {
    // ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šãƒã‚§ãƒƒã‚¯
    const { error: dbError } = await supabase
      .from('articles')
      .select('count')
      .limit(1);
    
    checks.checks.database = !dbError;

    // è¨˜äº‹æ•°ãƒã‚§ãƒƒã‚¯
    const { count } = await supabase
      .from('articles')
      .select('*', { count: 'exact', head: true })
      .eq('status', 'PUBLISHED');
    
    checks.checks.articles = count || 0;

    // æœ€çµ‚å…¬é–‹æ—¥ãƒã‚§ãƒƒã‚¯
    const { data: latest } = await supabase
      .from('articles')
      .select('published_at')
      .eq('status', 'PUBLISHED')
      .order('published_at', { ascending: false })
      .limit(1)
      .single();
    
    checks.checks.lastPublished = latest?.published_at || null;

    // å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹åˆ¤å®š
    if (!checks.checks.database) {
      checks.status = 'unhealthy';
    } else if (checks.checks.articles === 0) {
      checks.status = 'degraded';
    }

    return NextResponse.json(checks, {
      status: checks.status === 'healthy' ? 200 : 503,
    });
  } catch (error) {
    return NextResponse.json({
      status: 'unhealthy',
      timestamp: new Date().toISOString(),
      error: 'Health check failed',
    }, { status: 503 });
  }
}
```

### 5.4 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å¾©æ—§

#### 5.4.1 ãƒªãƒˆãƒ©ã‚¤ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ï¼ˆscripts/utils/retry.tsï¼‰
```typescript
export async function withRetry<T>(
  fn: () => Promise<T>,
  options: {
    maxAttempts?: number;
    delay?: number;
    backoff?: number;
    onRetry?: (attempt: number, error: Error) => void;
  } = {}
): Promise<T> {
  const {
    maxAttempts = 3,
    delay = 1000,
    backoff = 2,
    onRetry,
  } = options;

  let lastError: Error;

  for (let attempt = 1; attempt <= maxAttempts; attempt++) {
    try {
      return await fn();
    } catch (error) {
      lastError = error as Error;
      
      if (attempt < maxAttempts) {
        const waitTime = delay * Math.pow(backoff, attempt - 1);
        
        if (onRetry) {
          onRetry(attempt, lastError);
        }
        
        await new Promise(resolve => setTimeout(resolve, waitTime));
      }
    }
  }

  throw lastError!;
}

// ä½¿ç”¨ä¾‹
const result = await withRetry(
  () => fetchGuardianArticles(),
  {
    maxAttempts: 3,
    delay: 2000,
    onRetry: (attempt, error) => {
      console.log(`Retry attempt ${attempt}: ${error.message}`);
    },
  }
);
```

#### 5.4.2 å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆscripts/recovery.tsï¼‰
```typescript
import { supabaseAdmin } from '../src/lib/supabase';
import { Logger } from './utils/logger';

const logger = new Logger('recovery');

const recoverFailedArticles = async () => {
  logger.info('å¾©æ—§å‡¦ç†ã‚’é–‹å§‹');

  // å¤±æ•—ã—ãŸè¨˜äº‹ã‚’å–å¾—
  const { data: failedTopics } = await supabaseAdmin
    .from('topics')
    .select('*')
    .in('status', ['OUTLINED', 'DRAFTED'])
    .lt('updated_at', new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString())
    .order('score', { ascending: false });

  if (!failedTopics?.length) {
    logger.info('å¾©æ—§å¯¾è±¡ã®è¨˜äº‹ã¯ã‚ã‚Šã¾ã›ã‚“');
    return;
  }

  logger.info(`${failedTopics.length}ä»¶ã®è¨˜äº‹ã‚’å¾©æ—§å¯¾è±¡ã¨ã—ã¦æ¤œå‡º`);

  for (const topic of failedTopics) {
    try {
      // ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ãƒªã‚»ãƒƒãƒˆ
      await supabaseAdmin
        .from('topics')
        .update({ status: 'NEW' })
        .eq('id', topic.id);

      logger.info(`ãƒªã‚»ãƒƒãƒˆå®Œäº†: ${topic.title}`);
    } catch (error) {
      logger.error(`å¾©æ—§å¤±æ•—: ${topic.title}`, error as Error);
    }
  }

  logger.info('å¾©æ—§å‡¦ç†å®Œäº†');
  logger.close();
};

// ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
const cleanupOldData = async () => {
  logger.info('å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚’é–‹å§‹');

  // 30æ—¥ä»¥ä¸Šå‰ã®æœªä½¿ç”¨ã‚½ãƒ¼ã‚¹ã‚’å‰Šé™¤
  const cutoffDate = new Date(Date.now() - 30 * 24 * 60 * 60 * 1000);
  
  const { error } = await supabaseAdmin
    .from('sources')
    .delete()
    .lt('created_at', cutoffDate.toISOString())
    .is('processed_at', null);

  if (error) {
    logger.error('ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼', error);
  } else {
    logger.info('ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Œäº†');
  }

  logger.close();
};

// å®Ÿè¡Œ
if (require.main === module) {
  Promise.all([
    recoverFailedArticles(),
    cleanupOldData(),
  ]).catch(console.error);
}
```

### 5.5 ç’°å¢ƒå¤‰æ•°ç®¡ç†

#### 5.5.1 ç’°å¢ƒå¤‰æ•°ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆï¼ˆ.env.exampleï¼‰
```bash
# API Keys
GUARDIAN_API_KEY=your_guardian_api_key
NYT_API_KEY=your_nyt_api_key
OPENAI_API_KEY=your_openai_api_key
ANTHROPIC_API_KEY=your_anthropic_api_key

# Supabase
NEXT_PUBLIC_SUPABASE_URL=https://your-project.supabase.co
NEXT_PUBLIC_SUPABASE_ANON_KEY=your_anon_key
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Site Configuration
SITE_URL=https://your-domain.com
TZ=Asia/Tokyo

# Monitoring (Optional)
WEBHOOK_URL=https://hooks.slack.com/services/xxx
SENTRY_DSN=https://xxx@sentry.io/xxx

# Vercel (for deployment)
VERCEL_TOKEN=your_vercel_token
VERCEL_ORG_ID=your_org_id
VERCEL_PROJECT_ID=your_project_id
```

#### 5.5.2 ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆç®¡ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆscripts/setup-secrets.shï¼‰
```bash
#!/bin/bash

# GitHub Secretsã®è¨­å®š
echo "Setting up GitHub Secrets..."

# å¿…é ˆã®ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯
required_vars=(
  "GUARDIAN_API_KEY"
  "NYT_API_KEY"
  "OPENAI_API_KEY"
  "NEXT_PUBLIC_SUPABASE_URL"
  "NEXT_PUBLIC_SUPABASE_ANON_KEY"
  "SUPABASE_SERVICE_ROLE_KEY"
  "SITE_URL"
)

for var in "${required_vars[@]}"; do
  if [ -z "${!var}" ]; then
    echo "Error: $var is not set"
    exit 1
  fi
done

# GitHub CLIã‚’ä½¿ç”¨ã—ã¦ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã‚’è¨­å®š
gh secret set GUARDIAN_API_KEY --body "$GUARDIAN_API_KEY"
gh secret set NYT_API_KEY --body "$NYT_API_KEY"
gh secret set OPENAI_API_KEY --body "$OPENAI_API_KEY"
gh secret set ANTHROPIC_API_KEY --body "$ANTHROPIC_API_KEY"
gh secret set NEXT_PUBLIC_SUPABASE_URL --body "$NEXT_PUBLIC_SUPABASE_URL"
gh secret set NEXT_PUBLIC_SUPABASE_ANON_KEY --body "$NEXT_PUBLIC_SUPABASE_ANON_KEY"
gh secret set SUPABASE_SERVICE_ROLE_KEY --body "$SUPABASE_SERVICE_ROLE_KEY"
gh secret set SITE_URL --body "$SITE_URL"

echo "GitHub Secrets setup complete!"
```

## ãƒ†ã‚¹ãƒˆã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

### 5.6.1 ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰ãƒ†ã‚¹ãƒˆ
```typescript
// scripts/e2e-test.ts
const runE2ETest = async () => {
  console.log('E2Eãƒ†ã‚¹ãƒˆé–‹å§‹');

  // 1. ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ†ã‚¹ãƒˆ
  const fetchResult = await testDataFetch();
  assert(fetchResult.success, 'ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—');

  // 2. AIå‡¦ç†ãƒ†ã‚¹ãƒˆ
  const aiResult = await testAIProcessing();
  assert(aiResult.success, 'AIå‡¦ç†å¤±æ•—');

  // 3. å…¬é–‹ãƒ†ã‚¹ãƒˆ
  const publishResult = await testPublishing();
  assert(publishResult.success, 'å…¬é–‹å‡¦ç†å¤±æ•—');

  // 4. ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºãƒ†ã‚¹ãƒˆ
  const frontendResult = await testFrontendDisplay();
  assert(frontendResult.success, 'ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤ºå¤±æ•—');

  console.log('E2Eãƒ†ã‚¹ãƒˆå®Œäº†: ã™ã¹ã¦æˆåŠŸ');
};
```

### 5.6.2 è² è·ãƒ†ã‚¹ãƒˆ
```bash
# k6ã‚’ä½¿ç”¨ã—ãŸè² è·ãƒ†ã‚¹ãƒˆ
k6 run scripts/load-test.js

# Apache Benchã‚’ä½¿ç”¨
ab -n 1000 -c 10 https://your-domain.com/
```

## å®Œäº†åŸºæº–
- [ ] çµ±åˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- [ ] GitHub Actionsã®å®šæœŸå®Ÿè¡ŒãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹
- [ ] ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã‚·ã‚¹ãƒ†ãƒ ãŒæ©Ÿèƒ½ã—ã¦ã„ã‚‹
- [ ] ãƒ­ã‚°ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹
- [ ] ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒåˆ©ç”¨å¯èƒ½
- [ ] ãƒªãƒˆãƒ©ã‚¤ã¨ã‚¨ãƒ©ãƒ¼å¾©æ—§ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹
- [ ] ç’°å¢ƒå¤‰æ•°ã¨ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆãŒé©åˆ‡ã«ç®¡ç†ã•ã‚Œã¦ã„ã‚‹
- [ ] E2Eãƒ†ã‚¹ãƒˆãŒé€šéã—ã¦ã„ã‚‹

## é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«

### æ—¥æ¬¡ç¢ºèªé …ç›®
1. ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç¢ºèª
2. æœ€æ–°è¨˜äº‹ã®å…¬é–‹çŠ¶æ³ç¢ºèª
3. ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã®ç¢ºèª
4. APIåˆ©ç”¨é‡ã®ç¢ºèª

### é€±æ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
1. ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
2. å¤ã„ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ç¢ºèª
4. ã‚³ã‚¹ãƒˆåˆ†æï¼ˆAPIåˆ©ç”¨æ–™ï¼‰

### ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- **è¨˜äº‹ãŒå…¬é–‹ã•ã‚Œãªã„**: ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ­ã‚°ã‚’ç¢ºèªã€å¾©æ—§ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’å®Ÿè¡Œ
- **APIåˆ¶é™ã‚¨ãƒ©ãƒ¼**: ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã®èª¿æ•´ã€å®Ÿè¡Œé–“éš”ã®å¤‰æ›´
- **AIå‡¦ç†ã‚¨ãƒ©ãƒ¼**: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç¢ºèªã€APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ç¢ºèª
- **Supabaseæ¥ç¶šã‚¨ãƒ©ãƒ¼**: æ¥ç¶šæ•°åˆ¶é™ã®ç¢ºèªã€æ¥ç¶šãƒ—ãƒ¼ãƒ«ã®èª¿æ•´

## ã¾ã¨ã‚
Phase 5ã®å®Œäº†ã«ã‚ˆã‚Šã€World News Readerã®å®Œå…¨è‡ªå‹•é‹ç”¨ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚
å®šæœŸçš„ãªç›£è¦–ã¨ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ã«ã‚ˆã‚Šã€å®‰å®šã—ãŸã‚µãƒ¼ãƒ“ã‚¹æä¾›ã‚’å®Ÿç¾ã—ã¾ã™ã€‚